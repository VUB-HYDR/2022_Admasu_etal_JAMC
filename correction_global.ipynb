{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba5fa1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a169e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'cesm2'\n",
    "realisation = 'r1i1p1f1'\n",
    "tas = xr.open_dataset('CMIP/tas_'+model+'_180.nc')\n",
    "tas = tas.sel(lat = slice(-56,84))\n",
    "\n",
    "obs1 = xr.open_dataset('CMIP/Tair_merge.nc')\n",
    "obs1 = obs1.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "\n",
    "#import CESM data for grid reference\n",
    "elev_sub1 = xr.open_dataset('elev/elev_subnewtas_cesm2.nc')\n",
    "#elev_sub1 = elev_sub1.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "\n",
    "elev_grid_bl = xr.open_dataset('elev/elev_gridnewtas_cesm2.nc')\n",
    "#elev_grid_bl = elev_grid_bl.reindex(lat=list(reversed(elev_grid_bl.lat)))\n",
    "\n",
    "remap = 'mapped'\n",
    "\n",
    "tasmapped = xr.open_dataset('review_files/'+remap+'_tas_' + model + '_new.nc')\n",
    "tasmapped = tasmapped.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "tasunmapped = xr.open_dataset('CMIP/mnLut_'+ model +'_'+realisation+'_obs.nc')\n",
    "tasunmapped = tasunmapped.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1579e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = ssxym / ssxm\n",
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:189: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:192: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    }
   ],
   "source": [
    "#determine the number of lon and lat at GCM level inside study area\n",
    "reglon = len(tas.lon.values)\n",
    "reglat = len(tas.lat.values)\n",
    "\n",
    "#initialize lapse rate\n",
    "lapse = 0*obs1.Tair\n",
    "reg = 0*obs1.Tair\n",
    "\n",
    "for j in range(0,reglon-1,1):\n",
    "    for k in range (0,reglat-1,1):\n",
    "        #slice the data into 1 grid size of GCM model\n",
    "        lonslice = slice(tas.lon.values[j],tas.lon.values[j+1])\n",
    "        latslice = slice(tas.lat.values[k+1],tas.lat.values[k])\n",
    "            \n",
    "        obslice = obs1.sel(lon = lonslice, lat = latslice)\n",
    "        elevslice = elev_sub1.sel(lon = lonslice, lat =latslice)\n",
    "        lapslice = lapse.sel(lon = lonslice, lat = latslice)\n",
    "        #regslice = reg.sel(lon = lonslice, lat = latslice)\n",
    "        \n",
    "        #stack dataset\n",
    "        stacked_obs = obslice.Tair.stack(z = (\"lat\",\"lon\"))\n",
    "        stacked_elev = elevslice.Band1.stack(z = (\"lat\",\"lon\")).values\n",
    "        stacked_lapse = lapslice.stack(z = (\"lat\",\"lon\"))\n",
    "        #stacked_reg  = regslice.stack(z = (\"lat\",\"lon\"))\n",
    "        \n",
    "        # apply regression between observation and elevation for each timestep and determine slope\n",
    "        for l in range(144):\n",
    "            stacked_obs1 = stacked_obs.isel(time =l).values\n",
    "            mask = ~np.isnan(stacked_elev) & ~np.isnan(stacked_obs1)\n",
    "            try:\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(stacked_elev[mask],stacked_obs1[mask])\n",
    "                #rsq = r_value**2\n",
    "            except:\n",
    "                slope = np.nan\n",
    "                #r_value = np.nan\n",
    "            stacked_lapse.isel(time = l).values.fill(slope)\n",
    "            #stacked_reg.isel(time = l).values.fill(rsq)\n",
    "            \n",
    "        #unstacked lapse data for lon lat that is filled with the slope from regression\n",
    "        unstacked_lapse = stacked_lapse.unstack(\"z\")\n",
    "        #unstacked_reg = stacked_reg.unstack(\"z\")\n",
    "        lapse.loc[dict(lon = lonslice, lat = latslice)] = unstacked_lapse\n",
    "        #reg.loc[dict(lon = lonslice, lat = latslice)] = unstacked_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc6cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#now define the correction by multiplying lapse rate with elevation diference\n",
    "elev_difer = elev_sub1.Band1 - elev_grid_bl.Band1\n",
    "lapse=lapse.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "correction = elev_difer * lapse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5d39c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tascor = tasmapped.tas.copy(deep =True)\n",
    "tascor1 = tasunmapped.tasLut.copy(deep = True)\n",
    "\n",
    "\n",
    "for m in range(len(tasmapped.time.values)):\n",
    "        tascor[m,:,:] = tasmapped.tas.isel(time = m) + correction.isel(time = m)\n",
    "        tascor1[m,:,:] = tasunmapped.tasLut.isel(time = m) + correction.isel(time =m)\n",
    "        tascor[m,:,:] = tascor.isel(time = m).where(obs1.Tair.isel(time = m) >0)\n",
    "        tascor1[m,:,:] = tascor1.isel(time = m).where(obs1.Tair.isel(time = m) >0)\n",
    "\n",
    "#    rsq_list[i] = reg.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b779b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tascor=tascor.to_dataset()\n",
    "tascor1=tascor1.to_dataset()\n",
    "tascor.to_netcdf('review_files/'+remap+'_tascor_'+ model + '_2new.nc')\n",
    "tascor1.to_netcdf('review_files/mnlut_tascor_' + model + '_2new.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9322890",
   "metadata": {},
   "source": [
    "### Do the same for UKESM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59d7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for CESM\n",
    "model = 'ukesm'\n",
    "realisation = 'r1i1p1f2'\n",
    "tas = xr.open_dataset('CMIP/tas_'+model+'_180.nc')\n",
    "tas = tas.sel(lat = slice(-56,84))\n",
    "\n",
    "obs = xr.open_dataset('CMIP/Tair_merge.nc')\n",
    "obs = obs.sel(lat = slice(83.125,-55.625),lon = slice(-179.0625,179.0625))\n",
    "\n",
    "#import CESM data for grid reference\n",
    "elev_sub = xr.open_dataset('elev/elev_sub_uk.nc')\n",
    "\n",
    "elev_grid = xr.open_dataset('elev/elev_gridnew_ukesm.nc')\n",
    "\n",
    "remap = 'mapped'\n",
    "\n",
    "tasmapped = xr.open_dataset('review_files/'+remap+'_tas_' + model + '_new.nc')\n",
    "tasmapped = tasmapped.sel(lat = slice(83.125,-55.625),lon = slice(-179.0625,179.0625))\n",
    "tasunmapped = xr.open_dataset('CMIP/mnLut_'+ model +'_'+realisation+'_obs.nc')\n",
    "tasunmapped = tasunmapped.sel(lat = slice(83.125,-55.625),lon = slice(-179.0625,179.0625))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec721fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = ssxym / ssxm\n",
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:189: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:192: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    }
   ],
   "source": [
    "#determine the number of lon and lat at GCM level inside study area\n",
    "reglon = len(tas.lon.values)\n",
    "reglat = len(tas.lat.values)\n",
    "\n",
    "#initialize lapse rate\n",
    "lapse = 0*obs.Tair\n",
    "reg = 0*obs.Tair\n",
    "\n",
    "for j in range(0,reglon-1,1):\n",
    "    for k in range (0,reglat-1,1):\n",
    "        #slice the data into 1 grid size of GCM model\n",
    "        lonslice = slice(tas.lon.values[j],tas.lon.values[j+1])\n",
    "        latslice = slice(tas.lat.values[k+1],tas.lat.values[k])\n",
    "            \n",
    "        obslice = obs.sel(lon = lonslice, lat = latslice)\n",
    "        elevslice = elev_sub.sel(lon = lonslice, lat =latslice)\n",
    "        lapslice = lapse.sel(lon = lonslice, lat = latslice)\n",
    "        #regslice = reg.sel(lon = lonslice, lat = latslice)\n",
    "        \n",
    "        #stack dataset\n",
    "        stacked_obs = obslice.Tair.stack(z = (\"lat\",\"lon\"))\n",
    "        stacked_elev = elevslice.Band1.stack(z = (\"lat\",\"lon\")).values\n",
    "        stacked_lapse = lapslice.stack(z = (\"lat\",\"lon\"))\n",
    "        #stacked_reg  = regslice.stack(z = (\"lat\",\"lon\"))\n",
    "        \n",
    "        # apply regression between observation and elevation for each timestep and determine slope\n",
    "        for l in range(144):\n",
    "            stacked_obs1 = stacked_obs.isel(time =l).values\n",
    "            mask = ~np.isnan(stacked_elev) & ~np.isnan(stacked_obs1)\n",
    "            try:\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(stacked_elev[mask],stacked_obs1[mask])\n",
    "                #rsq = r_value**2\n",
    "            except:\n",
    "                slope = np.nan\n",
    "                #r_value = np.nan\n",
    "            stacked_lapse.isel(time = l).values.fill(slope)\n",
    "            #stacked_reg.isel(time = l).values.fill(rsq)\n",
    "            \n",
    "        #unstacked lapse data for lon lat that is filled with the slope from regression\n",
    "        unstacked_lapse = stacked_lapse.unstack(\"z\")\n",
    "        #unstacked_reg = stacked_reg.unstack(\"z\")\n",
    "        lapse.loc[dict(lon = lonslice, lat = latslice)] = unstacked_lapse\n",
    "        #reg.loc[dict(lon = lonslice, lat = latslice)] = unstacked_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1983ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#elev_grid = xr.open_dataset('elev/elev_small_' + model + '.nc')\n",
    "#now define the correction by multiplying lapse rate with elevation diference\n",
    "elev_difer = elev_sub.Band1 - elev_grid.Band1\n",
    "lapse=lapse.sel(lat = slice(83.125,-55.625),lon = slice(-179.0625,179.0625))\n",
    "correction = elev_difer * lapse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abf03d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmapped=tasmapped.sel(lat = slice(83.125,-55.625),lon = slice(-179.0625,179.0625))\n",
    "tasunmapped=tasunmapped.sel(lat = slice(83.125,-55.625),lon = slice(-179.0625,179.0625))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f224bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tascor = tasmapped.tas.copy(deep =True)\n",
    "tascor1 = tasunmapped.tasLut.copy(deep = True)\n",
    "\n",
    "for m in range(len(tasmapped.time.values)):\n",
    "        tascor[m,:,:] = tasmapped.tas.isel(time = m) + correction.isel(time = m)\n",
    "        tascor1[m,:,:] = tasunmapped.tasLut.isel(time = m) + correction.isel(time =m)\n",
    "        tascor[m,:,:] = tascor.isel(time = m).where(obs.Tair.isel(time = m) >0)\n",
    "        tascor1[m,:,:] = tascor1.isel(time = m).where(obs.Tair.isel(time = m) >0)\n",
    "\n",
    "#    rsq_list[i] = reg.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d4de9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tascor=tascor.to_dataset()\n",
    "tascor1=tascor1.to_dataset()\n",
    "tascor.to_netcdf('review_files/'+remap+'_tascor_'+ model + '_new.nc')\n",
    "tascor1.to_netcdf('review_files/mnlut_tascor_' + model + '_new.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c473a6b",
   "metadata": {},
   "source": [
    "### For LST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aa7945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = 'cesm2'\n",
    "realisation = 'r1i1p1f1'\n",
    "tas2 = xr.open_dataset('lstmip/tslsi_'+model+'_180.nc')\n",
    "tas2 = tas2.sel(lat = slice(-56,84))\n",
    "\n",
    "obs2 = xr.open_dataset('lstmip/modlst.nc')\n",
    "obs2 = obs2.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "\n",
    "#import CESM data for grid reference\n",
    "elev_sub2= xr.open_dataset('elev/elev_subnewlst_cesm2.nc')\n",
    "elev_grid2 = xr.open_dataset('elev/elev_gridnewlst_cesm2.nc')\n",
    "\n",
    "remap = 'mapped'\n",
    "\n",
    "tasmapped = xr.open_dataset('review_files/'+remap+'_tslsi_' + model + '_new.nc')\n",
    "tasmapped = tasmapped.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "tasunmapped = xr.open_dataset('lstmip/mnLut_'+ model +'_obs.nc')\n",
    "tasunmapped = tasunmapped.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1df0d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:175: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = ssxym / ssxm\n",
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:189: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r * np.sqrt(df / ((1.0 - r + TINY)*(1.0 + r + TINY)))\n",
      "/scratch/brussel/vo/000/bvo00012/vsc10314/miniconda/envs/env3/lib/python3.10/site-packages/scipy/stats/_stats_mstats_common.py:192: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope_stderr = np.sqrt((1 - r**2) * ssym / ssxm / df)\n"
     ]
    }
   ],
   "source": [
    "#determine the number of lon and lat at GCM level inside study area\n",
    "reglon = len(tas2.lon.values)\n",
    "reglat = len(tas2.lat.values)\n",
    "\n",
    "#initialize lapse rate\n",
    "lapse = 0*obs2.lst\n",
    "reg = 0*obs2.lst\n",
    "\n",
    "for j in range(0,reglon-1,1):\n",
    "    for k in range (0,reglat-1,1):\n",
    "        #slice the data into 1 grid size of GCM model\n",
    "        lonslice = slice(tas2.lon.values[j],tas2.lon.values[j+1])\n",
    "        latslice = slice(tas2.lat.values[k+1],tas2.lat.values[k])\n",
    "            \n",
    "        obslice = obs2.sel(lon = lonslice, lat = latslice)\n",
    "        elevslice = elev_sub2.sel(lon = lonslice, lat =latslice)\n",
    "        lapslice = lapse.sel(lon = lonslice, lat = latslice)\n",
    "        #regslice = reg.sel(lon = lonslice, lat = latslice)\n",
    "        \n",
    "        #stack dataset\n",
    "        stacked_obs = obslice.lst.stack(z = (\"lat\",\"lon\"))\n",
    "        stacked_elev = elevslice.Band1.stack(z = (\"lat\",\"lon\")).values\n",
    "        stacked_lapse = lapslice.stack(z = (\"lat\",\"lon\"))\n",
    "        #stacked_reg  = regslice.stack(z = (\"lat\",\"lon\"))\n",
    "        \n",
    "        # apply regression between observation and elevation for each timestep and determine slope\n",
    "        for l in range(144):\n",
    "            stacked_obs1 = stacked_obs.isel(time =l).values\n",
    "            mask = ~np.isnan(stacked_elev) & ~np.isnan(stacked_obs1)\n",
    "            try:\n",
    "                slope, intercept, r_value, p_value, std_err = stats.linregress(stacked_elev[mask],stacked_obs1[mask])\n",
    "                #rsq = r_value**2\n",
    "            except:\n",
    "                slope = np.nan\n",
    "                #r_value = np.nan\n",
    "            stacked_lapse.isel(time = l).values.fill(slope)\n",
    "            #stacked_reg.isel(time = l).values.fill(rsq)\n",
    "            \n",
    "        #unstacked lapse data for lon lat that is filled with the slope from regression\n",
    "        unstacked_lapse = stacked_lapse.unstack(\"z\")\n",
    "        #unstacked_reg = stacked_reg.unstack(\"z\")\n",
    "        lapse.loc[dict(lon = lonslice, lat = latslice)] = unstacked_lapse\n",
    "        #reg.loc[dict(lon = lonslice, lat = latslice)] = unstacked_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714adbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#now define the correction by multiplying lapse rate with elevation diference\n",
    "elev_difer = elev_sub2.Band1 - elev_grid2.Band1\n",
    "lapse = lapse.sel(lat = slice(83.4,-55.15),lon = slice(-180.0,178.75))\n",
    "correction = elev_difer * lapse\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0165e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tascor = tasmapped.tas.copy(deep =True)\n",
    "tascor1 = tasunmapped.tslsiLut.copy(deep = True)\n",
    "\n",
    "for m in range(len(tasmapped.time.values)):\n",
    "        tascor[m,:,:] = tasmapped.tas.isel(time = m) + correction.isel(time = m)\n",
    "        tascor1[m,:,:] = tasunmapped.tslsiLut.isel(time = m) + correction.isel(time =m)\n",
    "        tascor[m,:,:] = tascor.isel(time = m).where(obs2.lst.isel(time = m) >0)\n",
    "        tascor1[m,:,:] = tascor1.isel(time = m).where(obs2.lst.isel(time = m) >0)\n",
    "\n",
    "#    rsq_list[i] = reg.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5718d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tascor.to_netcdf('review_files/mapped_tslsicor_'+ model + '_2new.nc')\n",
    "tascor1.to_netcdf('review_files/mnlut_tslsicor_' + model + '_2new.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c4fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
